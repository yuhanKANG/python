{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "105b4f8f",
   "metadata": {},
   "source": [
    "# 텍스트 마이닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954faeab",
   "metadata": {},
   "source": [
    "- 과제 10/18 (2) 교재 p.488~496 예제 풀기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0837dea",
   "metadata": {},
   "source": [
    "## 클렌징"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a67b6de",
   "metadata": {},
   "source": [
    "### 텍스트 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e770b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73431f6",
   "metadata": {},
   "source": [
    "#### 문장 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de52aa79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 3\n",
      "['The Matrix is everywhere its all around us, here even in this room.', 'You can see it out your window or on your television.', 'You feel it when you go to work, or go to church or pay your taxes.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# p.492\n",
    "from nltk import sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "text_sample = 'The Matrix is everywhere its all around us, here even in this room. \\\n",
    "You can see it out your window or on your television. \\\n",
    "You feel it when you go to work, or go to church or pay your taxes.'\n",
    "\n",
    "sentences = sent_tokenize(text=text_sample)\n",
    "print(type(sentences), len(sentences))\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c30e5b",
   "metadata": {},
   "source": [
    "#### 단어 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a92fd76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 15\n",
      "['The', 'Matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "sentence = \"The Matrix is everywhere its all around us, here even in this room.\"\n",
    "words = word_tokenize(sentence)\n",
    "print(type(words), len(words))\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00043731",
   "metadata": {},
   "source": [
    "#### 문서에 대한 모든 단어 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f35e137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 3\n",
      "[['The', 'Matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.'], ['You', 'can', 'see', 'it', 'out', 'your', 'window', 'or', 'on', 'your', 'television', '.'], ['You', 'feel', 'it', 'when', 'you', 'go', 'to', 'work', ',', 'or', 'go', 'to', 'church', 'or', 'pay', 'your', 'taxes', '.']]\n"
     ]
    }
   ],
   "source": [
    "# p.494\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "\n",
    "# 여러 개의 문장으로 된 입력 데이터를 문장별로 단어 토큰화하게 만드는 함수 생성\n",
    "def tokenize_text(text):\n",
    "    # 문장별로 분리 토큰\n",
    "    sentences = sent_tokenize(text)\n",
    "    # 분리된 문장별 단어 토큰화\n",
    "    word_tokens = [word_tokenize(sentence) for sentence in sentences]\n",
    "    return word_tokens\n",
    "# 여러 문장에 대해 문장별 단어 토큰화 수행\n",
    "word_tokens = tokenize_text(text_sample)\n",
    "print(type(word_tokens), len(word_tokens))\n",
    "print(word_tokens)\n",
    "# 3개 문장을 문장별로 먼저 토큰화 해서 리스트 내포 형식이 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38492d19",
   "metadata": {},
   "source": [
    "### 스톱 워드 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "758344a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "760eb315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 stop words 개수: 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his']\n"
     ]
    }
   ],
   "source": [
    "print('영어 stop words 개수:', len(nltk.corpus.stopwords.words('english')))\n",
    "print(nltk.corpus.stopwords.words('english')[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592fd140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스톱워드 필터링으로 제거하여 의미 있는 단어만 추출\n",
    "import nltk\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "all_tokens = []\n",
    "# 3개의 문장별로 얻은 words_tokens list에 대해 스톱 워드를 제거하는 반복문\n",
    "for sentence in word_tokens :\n",
    "    filtered_words=[]\n",
    "    # 개별 문장별로 토큰화된 문장 list에 대해 스톱 워드를 제거하는 반복문\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419ab51d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
